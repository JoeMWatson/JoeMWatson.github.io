<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Recommended Reading</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
<style type="text/css">
.post-dates{display:inline;padding-right:10px}
.post-desc{font-style:italic}
.post-footer{font-style:italic}
body{margin:40px auto;max-width:800px;line-height:1.6;font-size:18px;color:#444;padding:0 10px}
h1,h2,h3{line-height:1.2}
</style>

<link href="https://fonts.googleapis.com/css?family=Crimson+Text|Questrial&display=swap" rel="stylesheet">
<style>
  a { color: #5579bd; }
body {
  font-family: 'Poppins', sans-serif;
  font-size: 16px;
}
h1, h2, h3, h4, h5, h6 {
  line-height: 1rem;
  color: #0000FF;
}

</style>
</head>
<body>
<header>
<h1 class="title">Recommended Reading</h1>
</header>
<p>Given I have utterly failed to write any posts so far this year, I thought I should maybe try starting with some easy low-hanging fruit. I started writing a draft for a conference submission recently, and during such a process I always reflect on the papers I admire as inspiration. Here is that list. I imagine this post will get updated from time to time, so watch out for some edits.<br />
<em><strong>Note</strong>: this list is purely an exercise in personal curation, it is by no means exhaustive.</em></p>
<h2 id="machine-learning">Machine Learning</h2>
<p><strong>A Unifying Review of Linear Gaussian Models</strong><br />
<em>Sam Roweis, Zoubin Ghahramani</em>; <a href="http://mlg.eng.cam.ac.uk/zoubin/papers/lds.pdf">pdf</a><br />
I feel this paper should be at the core of any undergraduate core ML course. Assuming knowledge of algorithms like PCA and Kalman filtering, this review gives you an appreciation about how taking the probabilistic perspective with latent variable models and inference knit all these seemingly disparate methods together.</p>
<p><strong>The Factor Graph Approach to Model-Based Signal Processing</strong><br />
<em>Hans-Andrea Loeliger, Justin Dauwels, Junli Hu, Sascha Korl, Li Ping, Frank R. Kschischang</em>; <a href="http://fab.cba.mit.edu/classes/S62.12/docs/Loeliger_factor_graph.pdf">pdf</a><br />
As someone who did a lot of signal processing in their undergrad and also found Probabilistic Graphical Models difficult to appreciate, I found this review is very handy. It presents a simple guide for constructing probabilistic signal processing algorithms, and as a result, you can naturally develop an appreciation and understanding of factor graphs and message passing methods. This paper was my bible when getting started on I2C.</p>
<p><strong>Active Learning with Statistical Models</strong><br />
<em>David Cohn, Zoubin Ghahramani, Michael Jordan</em>; <a href="https://papers.nips.cc/paper/1011-active-learning-with-statistical-models.pdf">pdf</a><br />
Active Learning is an interesting setting where ML graduates beyond just being ‘implementation-aware statistics’. I recommend Marc Toussaints’s talk at MLSS, <a href="https://www.youtube.com/watch?v=5rev-zVx1Ps">Bandits, Active Learning, Bayesian RL and Global Optimization</a>, for appreciating the relationship to RL and optimization.</p>
<h2 id="robotics">Robotics</h2>
<p><strong>Robot Dynamics and Control</strong><br />
<em>Mark Spong, Seth Hutchinson, Mathukumalli Vidyasagar</em>; <a href="http://home.deib.polimi.it/gini/robot/docs/spong.pdf">pdf</a><br />
I am kinda cheating here with a textbook, but when it comes to classical robotics Spong is always a good shout. I used this book a lot when I worked in the robotics industry.</p>
<p><strong>Lie Group Formulation of Articulated Rigid Body Dynamics</strong><br />
<em>Junggon Kim</em>; <a href="http://www.cs.cmu.edu/~junggon/tools/liegroupdynamics.pdf">pdf</a><br />
I find Lie Algebra equal parts beautiful and terrifying. This work offers an elegant, geometrical view of robot dynamics, and I think such perspectives are particularly valuable in this age of Deep Learning.</p>
<p><strong>Sequential Composition of Dynamically Dexterous Robot Behaviours</strong><br />
<em>R.R.Burridge, A. A. Rizzi, D.E.Koditschek</em>; <a href="https://deepblue.lib.umich.edu/bitstream/handle/2027.42/67990/10.1177_02783649922066385.pdf">pdf</a><br />
I’m pretty sure there is some beautiful unifying theory for funnel geometry, stability and value functions. In the meantime, this is a nice summary of the idea of cascading funnels for stable control laws.</p>
<p><strong>Optimization-based Locomotion Planning, Estimation, and Control Design for the Atlas Humanoid Robot</strong><br />
<em>Scott Kuindersma, Robin Deits, Maurice Fallon, Andres Valenzuela·Hongkai Dai, Frank Permenter, TwanKoolen, Pat Marion, Russ Tedrake</em>; <a href="http://www.robots.ox.ac.uk/~mobile/drs/Papers/2015AR_kuindersma.pdf">pdf</a><br />
This paper offers two invaluable things: a system-level view of how to do complex robotics, and how to use fancy algorithms in a real-world setting. Given the current emphasis on flailing MuJoCo Humanoids, I would like to see more papers like this.</p>
<h2 id="robot-learning">Robot Learning</h2>
<p><strong>A Survey on Policy Search for Robotics</strong><br />
<em>Marc Deisenroth, Gerhard Neumann, Jan Peters</em>; <a href="https://core.ac.uk/download/pdf/84341151.pdf">pdf</a><br />
Maybe now a bit out of date, but offers a (timeless) review of entropy regularization (REPS), EM (PoWER) and probabilistic models (PILCO) for reinforcement learning.</p>
<p><strong>Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes</strong><br />
<em>Marc Toussaint, Amos Storkey</em>; <a href="https://ipvs.informatik.uni-stuttgart.de/mlr/marc/publications/06-toussaint-ICML.pdf">pdf</a><br />
I find many control-as-inference papers struggle to find the right balance between principled statistics and classic control methods, producing either beautiful inference methods that are hard to use on real problems or just a standard control algorithm packaged with a few inference-inspired tweaks. This paper does a nice job of taking <a href="https://pdfs.semanticscholar.org/01aa/f5722c0bcb06d536a359e4a2223c7755e8f3.pdf">Attias’ planning paper</a> and applying it to MDPs. The handling of the discount factor is particularly illuminating.</p>
<p><strong>Learning Stable Non-Linear Dynamical Systems with Gaussian Mixture Models</strong><br />
<em>S. Mohammad Khansari-Zadeh, Aude Billard</em>; <a href="http://lasa.epfl.ch/publications/uploadedFiles/Khansari_Billard_TRO2011.pdf">pdf</a><br />
As a sucker for Gaussian mixture models and dynamical systems, I think this paper is neat. They show that by learning a generative model of demonstrations, using GMMs, the conditional distribution is a switching dynamical system that can be used for imitation learning. The stability-constrained optimization is also a nice touch.</p>
<p><strong>Dual Control for Approximate Bayesian Reinforcement Learning</strong><br />
<em>Edgar Klenske, Philipp Hennig</em>; <a href="http://jmlr.org/papers/volume17/15-162/15-162.pdf">pdf</a><br />
I feel the Dual Control problem (concurrent optimal control and system identification) is one of the core problems in Robot Learning. Unfortunately, it seems to be very intractable in practice. This paper offers a frank analysis of this fact, as well as a nice Bayesian RL framing, without killing all enthusiasm.</p>
</body>
</html>
